# AGENTS – Agents Rule of Two

이 문서는 **Meta의 Agents Rule of Two** 프레임워크를 기반으로 한  
AI 에이전트 보안 설계 규칙을 정의합니다.

핵심 목표:

1. **Prompt Injection 취약점으로 인한 최악의 결과를 방지**합니다.
2. 에이전트 설계 시 **세 가지 속성 중 최대 두 가지만 허용**하는 원칙을 따릅니다.
3. 에이전트 개발자가 **보안과 유틸리티 간의 트레이드오프**를 명확히 이해하고 의사결정할 수 있도록 돕습니다.

---

## 1. Agents Rule of Two 개요

### 1.1 핵심 원칙

**Agents Rule of Two**는 prompt injection이 근본적으로 해결되지 않은 상황에서,  
에이전트가 다음 세 가지 속성 중 **최대 두 가지만** 동시에 가져야 한다고 명시합니다:

**[A] Untrustworthy Inputs (신뢰할 수 없는 입력)**  
에이전트가 알 수 없는 출처의 데이터를 처리할 수 있는지 여부  
예: 외부 이메일, 웹 검색 결과, 사용자 입력 등

**[B] Sensitive Systems or Private Data (민감한 시스템 또는 개인 데이터)**  
에이전트가 민감한 정보나 시스템에 접근할 수 있는지 여부  
예: 사용자 개인정보, 프로덕션 데이터베이스, 내부 시스템 등

**[C] State Changes or External Communication (상태 변경 또는 외부 통신)**  
에이전트가 시스템 상태를 변경하거나 외부와 통신할 수 있는지 여부  
예: 이메일 전송, 데이터베이스 수정, API 호출 등

### 1.2 규칙 적용

- 세 가지 속성 중 **최대 두 가지만** 동시에 허용합니다.
- 세 가지가 모두 필요한 경우:
  - **새로운 세션(새로운 컨텍스트 윈도우)**을 시작하거나
  - **인간의 감독(human-in-the-loop)** 또는 **다른 신뢰할 수 있는 검증 수단**이 필요합니다.

### 1.3 공식 구성

가능한 구성:

- **[AB]**: 신뢰할 수 없는 입력 + 민감한 데이터 접근 (외부 통신/상태 변경 제한)
- **[AC]**: 신뢰할 수 없는 입력 + 외부 통신/상태 변경 (민감한 데이터 접근 제한)
- **[BC]**: 민감한 데이터 접근 + 외부 통신/상태 변경 (신뢰할 수 없는 입력 제한)

---

## 2. 공격 시나리오와 방어

### 2.1 Email-Bot 공격 예시

**공격 시나리오**:  
스팸 이메일에 prompt injection 문자열이 포함되어, 사용자의 Email-Bot이  
사용자의 개인 이메일 내용을 수집하여 공격자에게 전송하도록 지시합니다.

**공격이 성공하는 이유**:
- [A] 신뢰할 수 없는 입력 처리 (스팸 이메일)
- [B] 민감한 데이터 접근 (사용자 이메일함)
- [C] 외부 통신 (이메일 전송)

**Agents Rule of Two로 방어**:

- **[BC] 구성**: 신뢰할 수 있는 발신자(예: 가까운 친구)의 이메일만 처리하여 prompt injection 페이로드가 에이전트 컨텍스트에 도달하지 못하게 합니다.
- **[AC] 구성**: 민감한 데이터나 시스템에 접근하지 않도록 제한(예: 테스트 환경에서만 작동)하여 prompt injection이 도달해도 의미 있는 피해를 입히지 못하게 합니다.
- **[AB] 구성**: 신뢰할 수 있는 수신자에게만 이메일을 전송하거나, 인간이 초안 메시지 내용을 검증하도록 하여 공격자가 최종적으로 공격 체인을 완성하지 못하게 합니다.

---

## 3. 실제 사용 사례

### 3.1 Travel Agent Assistant [AB]

**설명**: 공개 여행 어시스턴트로, 질문에 답하고 사용자를 대신해 행동할 수 있습니다.

**요구사항**:
- [A] 웹 검색을 통해 최신 여행 정보를 얻어야 함
- [B] 사용자 개인정보에 접근하여 예약 및 구매 경험을 제공해야 함

**Rule of Two 적용**:
- [C] 제한: 외부 통신 및 상태 변경에 대한 예방적 제어
  - 모든 행동(예약, 보증금 지불 등)에 대해 인간 확인 요청
  - 웹 요청을 신뢰할 수 있는 소스에서만 반환된 URL로 제한 (에이전트가 구성한 URL 방문 금지)

### 3.2 Web Browsing Research Assistant [AC]

**설명**: 사용자를 대신해 웹 브라우저와 상호작용하여 연구를 수행하는 에이전트입니다.

**요구사항**:
- [C] 임의의 URL에 대한 많은 요청을 보내고 폼을 작성해야 함
- [A] 결과를 처리하고 필요에 따라 재계획해야 함

**Rule of Two 적용**:
- [B] 제한: 민감한 시스템 및 개인 데이터 접근에 대한 예방적 제어
  - 사전 로드된 세션 데이터 없이 제한적인 샌드박스에서 브라우저 실행
  - 에이전트의 개인정보 접근 제한(초기 프롬프트 외) 및 데이터 공유 방식에 대한 사용자 알림

### 3.3 High-Velocity Internal Coder [BC]

**설명**: 조직의 내부 인프라 전반에 걸쳐 코드를 생성하고 실행하여 엔지니어링 문제를 해결하는 에이전트입니다.

**요구사항**:
- [B] 의미 있는 문제를 해결하기 위해 프로덕션 시스템의 하위 집합에 접근해야 함
- [C] 이러한 시스템에 대한 상태 변경을 수행할 수 있어야 함
- 인간 감독은 방어 심층 전략으로 가치가 있지만, 개발자는 규모에서 작동하기 위해 인간 개입을 최소화하려고 합니다.

**Rule of Two 적용**:
- [A] 제한: 신뢰할 수 없는 데이터 소스에 대한 예방적 제어
  - 에이전트의 컨텍스트 윈도우 내에서 처리되는 모든 데이터 소스에 대해 작성자 계보(author-lineage)를 사용하여 필터링
  - 거짓 양성을 표시하고 에이전트가 데이터에 접근할 수 있도록 하는 인간 검토 프로세스 제공

### 3.4 세션 내 구성 전환

일반적인 프레임워크와 마찬가지로, 세부 사항은 중요합니다.  
추가 사용 사례를 활성화하기 위해 에이전트가 동일한 세션 내에서  
하나의 Agents Rule of Two 구성에서 다른 구성으로 전환하는 것이 안전할 수 있습니다.

**예시**: 인터넷에 접근하기 위해 [AC]로 시작하고,  
내부 시스템에 접근할 때 통신을 비활성화하여 [B]로 일방향 전환을 완료합니다.

이를 안전하게 수행하는 구체적인 방법은 간결함을 위해 생략되었지만,  
독자는 **공격 경로를 방해하는 것에 집중**하여 이를 추론할 수 있습니다.  
즉, [A] → [B] → [C]의 전체 체인을 완성하지 못하도록 공격을 방지합니다.

---

## 4. 제한사항

### 4.1 다른 위협 벡터

Agents Rule of Two를 만족하는 것이 다음을 보호하기에 **충분하지 않습니다**:

- 에이전트에 공통적인 다른 위협 벡터
  - 공격자 승격(attacker uplift)
  - 스팸 확산
  - 에이전트 실수
  - 환각(hallucination)
  - 과도한 권한 등
- Prompt injection의 낮은 영향 결과
  - 에이전트 응답의 오정보 등

### 4.2 방어 심층(Defense in Depth)

Agents Rule of Two를 적용하는 것이 위험 완화의 **종착역이 아닙니다**.

- Agents Rule of Two를 만족하는 설계도 여전히 실패할 수 있습니다
  - 예: 사용자가 경고 인터스티셜을 맹목적으로 확인하는 경우
- **방어 심층**은 단일 계층의 실패가 가능할 때 최고 위험 시나리오를 완화하는 중요한 구성 요소입니다
- Agents Rule of Two는 **최소 권한(least-privilege)** 같은 일반적인 보안 원칙의 **보완재**이며 **대체재가 아닙니다**

---

## 5. 보완 솔루션

Agents Rule of Two를 보완하는 추가 AI 보호 솔루션:

- **Llama Firewall**: 에이전트 보호를 조율
- **Prompt Guard**: 잠재적 prompt injection을 분류
- **Code Shield**: 불안전한 코드 제안을 줄임
- **Llama Guard**: 잠재적으로 유해한 콘텐츠를 분류

자세한 내용은 [Meta Llama Protections](https://llama.meta.com/docs/model-cards-and-prompt-formats/llama-guard/) 문서를 참조하세요.

---

## 6. 미래 전망

### 6.1 Model Context Protocol (MCP)

플러그 앤 플레이 에이전트 도구 호출을 위한 프로토콜(예: Model Context Protocol)의 채택과 함께  
새로운 위험과 기회가 나타나고 있습니다.

- 에이전트를 새 도구에 맹목적으로 연결하는 것은 재앙의 레시피가 될 수 있습니다
- **기본 보안(security-by-default)**을 내장된 Rule of Two 인식으로 활성화할 수 있는 잠재력이 있습니다
- 예: 지원하는 도구 호출에서 Agents Rule of Two 구성을 선언함으로써,  
  개발자는 작업이 정책에 따라 성공, 실패 또는 추가 승인을 요청할 것이라는 확신을 가질 수 있습니다

### 6.2 감독 승인 체크

에이전트가 더 유용해지고 기능이 성장함에 따라,  
일부 매우 인기 있는 사용 사례는 Agents Rule of Two에 깔끔하게 맞추기 어려울 것입니다.

예: 인간 감독이 방해가 되거나 비효율적인 백그라운드 프로세스

- 전통적인 소프트웨어 가드레일과 인간 승인은 현재 사용 사례에서  
  Agents Rule of Two를 만족시키는 선호되는 방법으로 계속됩니다
- 정렬 제어를 통해 Agents Rule of Two의 감독 승인 체크를 만족시키는 연구를 계속 추구합니다
  - 예: 감독 에이전트(oversight agents)
  - 예: 오픈 소스 LlamaFirewall 플랫폼

---

## 7. 이 문서를 읽는 에이전트에게

1. **Agents Rule of Two는 필수 프레임워크**입니다.  
   AI 에이전트를 설계하거나 구현할 때 항상 이 원칙을 고려합니다.

2. 세 가지 속성 [A], [B], [C] 중 **최대 두 가지만** 동시에 허용합니다.

3. 세 가지가 모두 필요한 경우:
   - 새로운 세션을 시작하거나
   - 인간 감독 또는 신뢰할 수 있는 검증 메커니즘을 도입합니다.

4. **방어 심층**을 고려합니다.  
   Agents Rule of Two는 다른 보안 원칙과 함께 사용되어야 합니다.

5. 모호한 부분이 있다면:
   - (대화 가능한 환경이면) 사용자에게 질문합니다.
   - 그렇지 않다면 가장 보수적인 가정으로 설계합니다.

이 프레임워크는 prompt injection의 최악의 결과를 결정적으로 줄이는 것을 목표로 합니다.  
에이전트 개발자가 보안과 유틸리티 간의 트레이드오프를 이해하고  
정보에 기반한 의사결정을 내릴 수 있도록 돕습니다.

---

## 참고 자료

- [Meta AI Blog: Agents Rule of Two - A Practical Approach to AI Agent Security](https://ai.meta.com/blog/practical-ai-agent-security/) (October 31, 2025)
- [Chromium Rule of Two](https://chromium.googlesource.com/chromium/src/+/main/docs/security/rule-of-two.md)
- [Simon Willison's "Lethal Trifecta"](https://simonwillison.net/2023/Oct/25/lethal-trifecta/)
- [Meta Llama Protections](https://llama.meta.com/docs/model-cards-and-prompt-formats/llama-guard/)

